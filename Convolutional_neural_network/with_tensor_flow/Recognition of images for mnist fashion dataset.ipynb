{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognition of images of the fashion mnist dataset\n",
    "\n",
    "## The project\n",
    "\n",
    "\n",
    "The aim of the project is to use differents techniques of deep learning in order to predict type of clothes of the fashion mnist dataset the more precisely possible.\n",
    "\n",
    "The dataset is compose of 60 000 images for training and 10 000 images for testing.\n",
    "\n",
    "<img src=\"img/Fashion-MNIST-Dataset-Images-with-Labels-and-Description.png\">\n",
    "\n",
    "There are 10 different classes, the neural network will have to predict for an image given what type of class it is.\n",
    "\n",
    "## The code\n",
    "\n",
    "We will begin our training by our more simple model : a linear model.\n",
    "\n",
    "First we need to import the packages we will need :\n",
    "\n",
    "```python\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "```\n",
    "\n",
    "Then we need to create our linear model using keras :\n",
    "\n",
    "```python\n",
    "\n",
    "def linear_model(x, y, val_x, val_y, opt, loss_func, epochs, batch_size):\n",
    "    model = keras.Sequential([\n",
    "        # convert a two dimensional matrix into a vector\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(10, activation=keras.activations.softmax),\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=opt, loss=loss_func, metrics=keras.metrics.categorical_accuracy)\n",
    "\n",
    "    logs = model.fit(x, y, validation_data=(val_x, val_y), epochs=epochs, batch_size=batch_size,\n",
    "                     callbacks=[keras.callbacks.LearningRateScheduler(scheduler)])\n",
    "    model.summary()\n",
    "\n",
    "    return logs\n",
    "\n",
    "```\n",
    "\n",
    "The model take in parameter :\n",
    "\n",
    "* The training and testing datas\n",
    "* The function of optimization\n",
    "* The function for evaluate the loss\n",
    "* The epochs (number of time the neural network process the entire datset)\n",
    "* The batch size (number of example given before the neural network corrige the weights\n",
    "\n",
    "Here we choose for the activation function the softmax because the sum of the output returned is 1 and it is useful in a categorical problem.\n",
    "\n",
    "In the main function :\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # how many time the model will review the training data\n",
    "    epochs = 50\n",
    "    # number of data images who spreed through the network (forward propagation), after that the network\n",
    "    # mean the sum of errors and make only one backpropagation\n",
    "    # batch size increase the available computational parallelism and make it converge faster to optimum local\n",
    "    # but algorithm with large batch size will hardly find the minimum global compared to little bach size\n",
    "    batch_size = 1024\n",
    "\n",
    "    # get data of training and testing from fashion mnist dataset\n",
    "    (x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "    # pixel have values from 0 to 255, normalize them\n",
    "    x_train = x_train / 255.0\n",
    "    x_test = x_test / 255.0\n",
    "\n",
    "    # transform label (containing a value from O to 9) to matrix of 10 (one hot encoding)\n",
    "    y_train = keras.utils.to_categorical(y_train, 10)\n",
    "    y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "    all_logs = []\n",
    "    log = linear_model(x_train, y_train, x_test, y_test, keras.optimizers.SGD(lr=0.05, momentum=0.95),\n",
    "                       keras.losses.categorical_crossentropy, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "    all_logs.append(log)\n",
    "\n",
    "    plot_log(all_logs)\n",
    "\n",
    "```\n",
    "So firstly we introduce hyperparameters epochs and batch_size and set it respectively to 50 and 1024.\n",
    "A large batch size will allow the network to process the data much faster but there at risk that it converge in global (and not local) optimum.\n",
    "\n",
    "For the loss function, cross-entropy is used as it is a good function coupled to the softmax functions as it penalized well the deviations between output and predicted values.\n",
    "\n",
    "The function plot_log allow us to display the loss and accuracy of our models.\n",
    "\n",
    "After 50 epochs, here are our results :"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
